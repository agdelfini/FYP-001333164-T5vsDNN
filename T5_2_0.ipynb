{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agdelfini/FYP-001333164-T5vsDNN/blob/main/T5_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n"
      ],
      "metadata": {
        "id": "JtMV0IGAV_d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T08:58:36.185686Z",
          "iopub.execute_input": "2023-03-22T08:58:36.186364Z",
          "iopub.status.idle": "2023-03-22T08:58:54.630219Z",
          "shell.execute_reply.started": "2023-03-22T08:58:36.186325Z",
          "shell.execute_reply": "2023-03-22T08:58:54.628991Z"
        },
        "trusted": true,
        "id": "sAmjK3xZFmrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:09.214373Z",
          "iopub.execute_input": "2023-03-22T07:09:09.214697Z",
          "iopub.status.idle": "2023-03-22T07:09:19.645547Z",
          "shell.execute_reply.started": "2023-03-22T07:09:09.214663Z",
          "shell.execute_reply": "2023-03-22T07:09:19.644036Z"
        },
        "trusted": true,
        "id": "tiFinYhcFmrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rouge_score import rouge_scorer\n",
        "from tqdm.auto import tqdm\n",
        "import torch"
      ],
      "metadata": {
        "id": "gSpLIhhV6982"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import lightning as pl"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:19.647511Z",
          "iopub.execute_input": "2023-03-22T07:09:19.647976Z",
          "iopub.status.idle": "2023-03-22T07:09:32.513035Z",
          "shell.execute_reply.started": "2023-03-22T07:09:19.647927Z",
          "shell.execute_reply": "2023-03-22T07:09:32.511910Z"
        },
        "trusted": true,
        "id": "JTWw7aWJFmrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored\n",
        "import textwrap"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:32.516036Z",
          "iopub.execute_input": "2023-03-22T07:09:32.516712Z",
          "iopub.status.idle": "2023-03-22T07:09:32.826880Z",
          "shell.execute_reply.started": "2023-03-22T07:09:32.516667Z",
          "shell.execute_reply": "2023-03-22T07:09:32.825822Z"
        },
        "trusted": true,
        "id": "_chKpJdqFmrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from lightning.pytorch import Trainer\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "from transformers import T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer\n",
        "from torch.optim import AdamW\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:32.828569Z",
          "iopub.execute_input": "2023-03-22T07:09:32.829005Z",
          "iopub.status.idle": "2023-03-22T07:09:32.850505Z",
          "shell.execute_reply.started": "2023-03-22T07:09:32.828951Z",
          "shell.execute_reply": "2023-03-22T07:09:32.849255Z"
        },
        "trusted": true,
        "id": "9zw7gZVSFmrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:32.852277Z",
          "iopub.execute_input": "2023-03-22T07:09:32.852679Z",
          "iopub.status.idle": "2023-03-22T07:09:33.045173Z",
          "shell.execute_reply.started": "2023-03-22T07:09:32.852639Z",
          "shell.execute_reply": "2023-03-22T07:09:33.043142Z"
        },
        "trusted": true,
        "id": "WDoaArSkFmrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(1234)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:33.052747Z",
          "iopub.execute_input": "2023-03-22T07:09:33.053263Z",
          "iopub.status.idle": "2023-03-22T07:09:33.079633Z",
          "shell.execute_reply.started": "2023-03-22T07:09:33.053222Z",
          "shell.execute_reply": "2023-03-22T07:09:33.078415Z"
        },
        "trusted": true,
        "id": "wp4JM0ssFmrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/news_summary.csv\", encoding=\"latin-1\")"
      ],
      "metadata": {
        "id": "H7AfmkZnRRdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:33.550487Z",
          "iopub.execute_input": "2023-03-22T07:09:33.551282Z",
          "iopub.status.idle": "2023-03-22T07:09:33.559772Z",
          "shell.execute_reply.started": "2023-03-22T07:09:33.551242Z",
          "shell.execute_reply": "2023-03-22T07:09:33.558510Z"
        },
        "trusted": true,
        "id": "OdqD2db0Fmri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.1)\n",
        "print(f\"Shape of the Train Set: {train_df.shape}\\nShape of the Test Set: {test_df.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:33.561924Z",
          "iopub.execute_input": "2023-03-22T07:09:33.562604Z",
          "iopub.status.idle": "2023-03-22T07:09:33.572972Z",
          "shell.execute_reply.started": "2023-03-22T07:09:33.562566Z",
          "shell.execute_reply": "2023-03-22T07:09:33.571696Z"
        },
        "trusted": true,
        "id": "r3vnKF45Fmri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, text_max_token_len=512, summary_max_token_len=128):\n",
        "        \"\"\"\n",
        "        A dataset that represents news articles and their respective summaries.\n",
        "\n",
        "        Args:\n",
        "        - data (pd.DataFrame): The data that contains the news articles and their summaries.\n",
        "        - tokenizer (transformers.tokenization_*) : The tokenizer used to tokenize the text and summary.\n",
        "        - text_max_token_len (int, optional): The maximum length of the text in terms of tokens. Defaults to 512.\n",
        "        - summary_max_token_len (int, optional): The maximum length of the summary in terms of tokens. Defaults to 128.\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.text_max_token_len = text_max_token_len\n",
        "        self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "        - The number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Get a sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "        - index (int): The index of the sample to get.\n",
        "\n",
        "        Returns:\n",
        "        - A dictionary that contains the following:\n",
        "            - text (str): The original text of the news article.\n",
        "            - summary (str): The summary of the news article.\n",
        "            - text_input_ids (torch.Tensor): The input IDs of the text after tokenization.\n",
        "            - text_attention_mask (torch.Tensor): The attention mask of the text after tokenization.\n",
        "            - labels (torch.Tensor): The input IDs of the summary after tokenization.\n",
        "            - labels_attention_mask (torch.Tensor): The attention mask of the summary after tokenization.\n",
        "        \"\"\"\n",
        "        data_row = self.data.iloc[index]\n",
        "        text = \"summarize: \" + str(data_row[\"ctext\"])\n",
        "\n",
        "        # Encode the text\n",
        "        text_encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.text_max_token_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Encode the summary\n",
        "        summary_encoding = self.tokenizer(\n",
        "            str(data_row[\"text\"]),\n",
        "            max_length=self.summary_max_token_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Modify the labels so that the model knows which tokens to predict\n",
        "        labels = summary_encoding['input_ids']\n",
        "        labels[labels == 0] = -100\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'summary': str(data_row['text']),\n",
        "            'text_input_ids': text_encoding['input_ids'].flatten(),\n",
        "            'text_attention_mask': text_encoding['attention_mask'].flatten(),\n",
        "            'labels': labels.flatten(),\n",
        "            'labels_attention_mask': summary_encoding[\"attention_mask\"].flatten()\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:33.583900Z",
          "iopub.execute_input": "2023-03-22T07:09:33.584279Z",
          "iopub.status.idle": "2023-03-22T07:09:33.597835Z",
          "shell.execute_reply.started": "2023-03-22T07:09:33.584242Z",
          "shell.execute_reply": "2023-03-22T07:09:33.596594Z"
        },
        "trusted": true,
        "id": "Ha6aqzrmFmri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataModule(pl.LightningDataModule):\n",
        "    def __init__(self,\n",
        "                 train_df,\n",
        "                 test_df,\n",
        "                 tokenizer,\n",
        "                 batch_size=8,\n",
        "                 text_max_token_len=152,\n",
        "                 summary_max_token_len=128):\n",
        "        \"\"\"\n",
        "        Initializes the NewsDataModule.\n",
        "\n",
        "        Args:\n",
        "        - train_df (pandas.DataFrame): the training dataset\n",
        "        - test_df (pandas.DataFrame): the testing dataset\n",
        "        - tokenizer (transformers.PreTrainedTokenizer): the tokenizer to be used\n",
        "        - batch_size (int): the batch size\n",
        "        - text_max_token_len (int): the maximum number of tokens for the text\n",
        "        - summary_max_token_len (int): the maximum number of tokens for the summary\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_max_token_len = text_max_token_len\n",
        "        self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"\n",
        "        Sets up the dataset.\n",
        "        \"\"\"\n",
        "        self.train_dataset = NewsDataset(\n",
        "            self.train_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len)\n",
        "\n",
        "        self.test_dataset = NewsDataset(\n",
        "            self.test_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns the DataLoader for the training set.\n",
        "        \"\"\"\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns the DataLoader for the testing set.\n",
        "        \"\"\"\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns the DataLoader for the validation set, which is the same as the testing set.\n",
        "        \"\"\"\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False\n",
        "        )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:33.613488Z",
          "iopub.execute_input": "2023-03-22T07:09:33.613852Z",
          "iopub.status.idle": "2023-03-22T07:09:33.628026Z",
          "shell.execute_reply.started": "2023-03-22T07:09:33.613817Z",
          "shell.execute_reply": "2023-03-22T07:09:33.627066Z"
        },
        "trusted": true,
        "id": "8ngYYdHCFmri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:33.629744Z",
          "iopub.execute_input": "2023-03-22T07:09:33.630122Z",
          "iopub.status.idle": "2023-03-22T07:09:34.992024Z",
          "shell.execute_reply.started": "2023-03-22T07:09:33.630067Z",
          "shell.execute_reply": "2023-03-22T07:09:34.990872Z"
        },
        "trusted": true,
        "id": "SIoH0QFdFmrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_token_counts = [len(tokenizer.encode(str(row[\"ctext\"]))) for _, row in train_df.iterrows()]\n",
        "summary_token_counts = [len(tokenizer.encode(str(row[\"text\"]))) for _, row in train_df.iterrows()]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:34.993955Z",
          "iopub.execute_input": "2023-03-22T07:09:34.997411Z",
          "iopub.status.idle": "2023-03-22T07:09:43.785293Z",
          "shell.execute_reply.started": "2023-03-22T07:09:34.997367Z",
          "shell.execute_reply": "2023-03-22T07:09:43.784260Z"
        },
        "trusted": true,
        "id": "fMOtth5WFmrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 3\n",
        "BATCH_SIZE=8\n",
        "\n",
        "data_module = NewsDataModule(\n",
        "    train_df,\n",
        "    test_df,\n",
        "    tokenizer,\n",
        "    batch_size=BATCH_SIZE\n",
        "\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:45.628575Z",
          "iopub.execute_input": "2023-03-22T07:09:45.628871Z",
          "iopub.status.idle": "2023-03-22T07:09:45.637106Z",
          "shell.execute_reply.started": "2023-03-22T07:09:45.628843Z",
          "shell.execute_reply": "2023-03-22T07:09:45.636116Z"
        },
        "trusted": true,
        "id": "Nb6IpOVNFmrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "gyDrwVjlFmrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from nltk import sent_tokenize\n",
        "import nltk\n",
        "\n",
        "# Ensure nltk resources are downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "def calculate_novelty_score(source_text, generated_summary, n_sentences_bias=3):\n",
        "    \"\"\"\n",
        "    Calculates Novelty Score based on how different the summary is\n",
        "    from the lead sentences (Lead-3 bias).\n",
        "    \"\"\"\n",
        "    # 1. Extract the \"Lead-3\" (Introduction)\n",
        "    sentences = sent_tokenize(source_text)\n",
        "    lead_text = \" \".join(sentences[:n_sentences_bias])\n",
        "\n",
        "    # 2. Calculate n-gram overlap (using ROUGE-2 precision as a proxy for overlap)\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
        "    scores = scorer.score(lead_text, generated_summary)\n",
        "\n",
        "    # Precision = How much of the summary appears in the lead text?\n",
        "    overlap_score = scores['rouge2'].precision\n",
        "\n",
        "    # 3. Novelty is the inverse of overlap\n",
        "    # If overlap is 1.0 (100%), Novelty is 0.0.\n",
        "    # If overlap is 0.0, Novelty is 1.0.\n",
        "    novelty_score = 1.0 - overlap_score\n",
        "\n",
        "    return novelty_score"
      ],
      "metadata": {
        "id": "xnokEVTP6SA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummaryModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adafactor(\n",
        "            self.parameters(),\n",
        "            lr=1e-3,\n",
        "            eps=(1e-30, 1e-3),\n",
        "            clip_threshold=1.0,\n",
        "            decay_rate=-0.8,\n",
        "            beta1=None,\n",
        "            weight_decay=0.0,\n",
        "            relative_step=False,\n",
        "            scale_parameter=False,\n",
        "            warmup_init=False\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
        "        output = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            decoder_attention_mask=decoder_attention_mask\n",
        "        )\n",
        "        return output.loss, output.logits\n",
        "\n",
        "    def shared_step(self, batch, batch_idx, stage):\n",
        "        input_ids = batch['text_input_ids']\n",
        "        attention_mask = batch[\"text_attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "        loss, _ = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_attention_mask=labels_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        self.log(f\"{stage}_loss\", loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, batch_idx, 'train')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, batch_idx, 'val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, batch_idx, 'test')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=0.0001)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:45.649294Z",
          "iopub.execute_input": "2023-03-22T07:09:45.649843Z",
          "iopub.status.idle": "2023-03-22T07:09:45.662509Z",
          "shell.execute_reply.started": "2023-03-22T07:09:45.649807Z",
          "shell.execute_reply": "2023-03-22T07:09:45.661607Z"
        },
        "trusted": true,
        "id": "RVGg9wVHFmrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = SummaryModel()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:09:45.663655Z",
          "iopub.execute_input": "2023-03-22T07:09:45.664627Z",
          "iopub.status.idle": "2023-03-22T07:09:54.188836Z",
          "shell.execute_reply.started": "2023-03-22T07:09:45.664590Z",
          "shell.execute_reply": "2023-03-22T07:09:54.187776Z"
        },
        "trusted": true,
        "id": "5ao5t4ifFmrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = ModelCheckpoint(\n",
        "    dirpath=\"/kaggle/working/checkpoints\",\n",
        "    filename=\"base-checkpoint\",\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name=\"news_summary\")\n",
        "\n",
        "trainer= Trainer(\n",
        "    logger=logger,\n",
        "    callbacks=callbacks,\n",
        "    max_epochs=N_EPOCHS,\n",
        "    accelerator='gpu',\n",
        "    devices=1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:10:02.298903Z",
          "iopub.execute_input": "2023-03-22T07:10:02.300110Z",
          "iopub.status.idle": "2023-03-22T07:10:02.390134Z",
          "shell.execute_reply.started": "2023-03-22T07:10:02.300068Z",
          "shell.execute_reply": "2023-03-22T07:10:02.389155Z"
        },
        "trusted": true,
        "id": "gwRq6uoGFmrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model_1, data_module)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:10:34.242092Z",
          "iopub.execute_input": "2023-03-22T07:10:34.242812Z",
          "iopub.status.idle": "2023-03-22T07:19:53.348280Z",
          "shell.execute_reply.started": "2023-03-22T07:10:34.242773Z",
          "shell.execute_reply": "2023-03-22T07:19:53.347170Z"
        },
        "trusted": true,
        "id": "wpuskmRuFmrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = SummaryModel.load_from_checkpoint(\n",
        "    trainer.checkpoint_callback.best_model_path\n",
        ")\n",
        "best_model.freeze()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:21:19.518589Z",
          "iopub.execute_input": "2023-03-22T07:21:19.519567Z",
          "iopub.status.idle": "2023-03-22T07:21:31.453989Z",
          "shell.execute_reply.started": "2023-03-22T07:21:19.519516Z",
          "shell.execute_reply": "2023-03-22T07:21:31.452795Z"
        },
        "trusted": true,
        "id": "HQa-0z9GFmrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_text(text):\n",
        "    # Encode the text using the tokenizer\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    # Move tensors to the GPU\n",
        "    input_ids = encoding[\"input_ids\"].to(best_model.device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(best_model.device)\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "def generate_summary(input_ids, attention_mask):\n",
        "    generated_ids = best_model.model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=150,\n",
        "\n",
        "        # --- RETURN TO ACCURACY SETTINGS ---\n",
        "        num_beams=4,             # Beam Search is smarter/more accurate than Sampling\n",
        "        do_sample=False,         # Turn off random sampling to stop hallucinations\n",
        "\n",
        "        # --- FORCE NOVELTY WITHOUT RANDOMNESS ---\n",
        "        no_repeat_ngram_size=3,  # STRICT: The model cannot repeat any 3-word phrase it already wrote.\n",
        "        repetition_penalty=2.0,  # Punish repeating words generally\n",
        "\n",
        "        length_penalty=1.0,      # Ensure it doesn't cut off too short\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return generated_ids\n",
        "\n",
        "def decode_summary(generated_ids):\n",
        "    # Decode the generated summary\n",
        "    summary = [tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "               for gen_id in generated_ids]\n",
        "    return \"\".join(summary)\n",
        "\n",
        "def summarize(text):\n",
        "    input_ids, attention_mask = encode_text(text)\n",
        "    generated_ids = generate_summary(input_ids, attention_mask)\n",
        "    summary = decode_summary(generated_ids)\n",
        "    return summary"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:22:23.941887Z",
          "iopub.execute_input": "2023-03-22T07:22:23.942352Z",
          "iopub.status.idle": "2023-03-22T07:22:23.950851Z",
          "shell.execute_reply.started": "2023-03-22T07:22:23.942290Z",
          "shell.execute_reply": "2023-03-22T07:22:23.949641Z"
        },
        "trusted": true,
        "id": "hh9PLL1KFmrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_row = test_df.iloc[150]\n",
        "text = sample_row[\"text\"]\n",
        "model_summary = summarize(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:22:29.141107Z",
          "iopub.execute_input": "2023-03-22T07:22:29.141605Z",
          "iopub.status.idle": "2023-03-22T07:22:38.229443Z",
          "shell.execute_reply.started": "2023-03-22T07:22:29.141561Z",
          "shell.execute_reply": "2023-03-22T07:22:38.228369Z"
        },
        "trusted": true,
        "id": "4c_UzFqcFmrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:22:44.750337Z",
          "iopub.execute_input": "2023-03-22T07:22:44.751015Z",
          "iopub.status.idle": "2023-03-22T07:22:44.757354Z",
          "shell.execute_reply.started": "2023-03-22T07:22:44.750977Z",
          "shell.execute_reply": "2023-03-22T07:22:44.756338Z"
        },
        "trusted": true,
        "id": "cqUXIdB1Fmrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_row[\"text\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:22:47.696765Z",
          "iopub.execute_input": "2023-03-22T07:22:47.697125Z",
          "iopub.status.idle": "2023-03-22T07:22:47.704418Z",
          "shell.execute_reply.started": "2023-03-22T07:22:47.697091Z",
          "shell.execute_reply": "2023-03-22T07:22:47.703266Z"
        },
        "trusted": true,
        "id": "JZPk3LlbFmrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_summary"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-22T07:22:50.369197Z",
          "iopub.execute_input": "2023-03-22T07:22:50.369973Z",
          "iopub.status.idle": "2023-03-22T07:22:50.376533Z",
          "shell.execute_reply.started": "2023-03-22T07:22:50.369935Z",
          "shell.execute_reply": "2023-03-22T07:22:50.375324Z"
        },
        "trusted": true,
        "id": "EJiUOVJgFmrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rouge_score import rouge_scorer\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Setup the ROUGE Scorer\n",
        "# We use 'rougeL' for the Novelty score and all three for the general evaluation\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "def calculate_metrics_for_row(source_text, reference_summary, generated_summary):\n",
        "    \"\"\"\n",
        "    Calculates Standard ROUGE (Gen vs Ref) and Novelty (Gen vs Source).\n",
        "    \"\"\"\n",
        "    # --- Part A: Standard ROUGE Metrics (Success vs Reference) ---\n",
        "    # Compare Generated Summary vs Human Reference Summary\n",
        "    # We take the F-measure (fmeasure) as the standard aggregate score\n",
        "    scores = scorer.score(reference_summary, generated_summary)\n",
        "    rouge1 = scores['rouge1'].fmeasure\n",
        "    rouge2 = scores['rouge2'].fmeasure\n",
        "    rougel = scores['rougeL'].fmeasure\n",
        "\n",
        "    # --- Part B: Novelty Score (N) ---\n",
        "    # Definition: N = 1 - Granularity (G)\n",
        "    # Granularity = ROUGE-L(Summary, Full Text)\n",
        "    # We use Precision here because we want to know how much of the Summary\n",
        "    # is composed of content found directly in the Full Text.\n",
        "    granularity_scores = scorer.score(source_text, generated_summary)\n",
        "\n",
        "    # G: How much of the summary overlaps with the text? (Precision)\n",
        "    granularity = granularity_scores['rougeL'].precision\n",
        "\n",
        "    # N: Non-redundant information capacity\n",
        "    novelty = 1.0 - granularity\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": rouge1,\n",
        "        \"rouge2\": rouge2,\n",
        "        \"rougeL\": rougel,\n",
        "        \"novelty\": novelty,\n",
        "        \"granularity\": granularity\n",
        "    }\n",
        "\n",
        "def evaluate_model(model, tokenizer, test_data, num_samples=50):\n",
        "    \"\"\"\n",
        "    Runs inference on a subset of the test data and calculates metrics.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    metrics_list = []\n",
        "\n",
        "    # Select a subset to save time (Generation is slow!)\n",
        "    # Change num_samples=len(test_data) for full evaluation\n",
        "    test_subset = test_data.iloc[:num_samples]\n",
        "\n",
        "    print(f\"Starting evaluation on {len(test_subset)} samples...\")\n",
        "\n",
        "    for index, row in tqdm(test_subset.iterrows(), total=len(test_subset)):\n",
        "        source_text = str(row['ctext'])\n",
        "        reference_summary = str(row['text'])\n",
        "\n",
        "        # 1. Generate Summary using your existing summarize function\n",
        "        try:\n",
        "            generated_summary = summarize(source_text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating summary for index {index}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 2. Calculate Metrics\n",
        "        metrics = calculate_metrics_for_row(source_text, reference_summary, generated_summary)\n",
        "        metrics_list.append(metrics)\n",
        "\n",
        "    return pd.DataFrame(metrics_list)\n",
        "\n",
        "# --- Run the Evaluation ---\n",
        "# We limit to 50 samples for speed. Increase this number for better accuracy.\n",
        "results_df = evaluate_model(best_model, tokenizer, test_df, num_samples=50)\n",
        "\n",
        "# --- Calculate and Print Averages ---\n",
        "avg_results = results_df.mean()\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"FINAL EVALUATION METRICS\")\n",
        "print(\"=\"*40)\n",
        "print(f\"ROUGE-1 (F1)   : {avg_results['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2 (F1)   : {avg_results['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L (F1)   : {avg_results['rougeL']:.4f}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Granularity (G) : {avg_results['granularity']:.4f}\")\n",
        "print(f\"Novelty (N)     : {avg_results['novelty']:.4f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "\n",
        "# --- Visual Comparison of a Specific Example ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"EXAMPLE COMPARISON\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Let's take the first item from our test set\n",
        "sample_row = test_df.iloc[0]\n",
        "sample_source = str(sample_row['ctext'])\n",
        "sample_ref = str(sample_row['text'])\n",
        "\n",
        "# Generate T5 Summary\n",
        "sample_gen = summarize(sample_source)\n",
        "\n",
        "# Calculate metrics for this specific example\n",
        "sample_metrics = calculate_metrics_for_row(sample_source, sample_ref, sample_gen)\n",
        "\n",
        "print(f\"**Original Article:**\\n\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"**Original Reference Summary (Human):**\\n{sample_ref}\\n\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"**T5 Generated Summary (Model):**\\n{sample_gen}\\n\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"**Metrics for this example:**\")\n",
        "print(f\"Novelty: {sample_metrics['novelty']:.4f} | ROUGE-1: {sample_metrics['rouge1']:.4f}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "gsho5TtXVmKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}